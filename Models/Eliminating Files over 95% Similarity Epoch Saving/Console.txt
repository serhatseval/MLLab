Epoch 1
-------------------------------
loss: 0.713550  [   16/23057]
loss: 0.570037  [ 1616/23057]
loss: 0.503052  [ 3216/23057]
loss: 0.344974  [ 4816/23057]
loss: 0.661167  [ 6416/23057]
loss: 0.252718  [ 8016/23057]
loss: 0.251722  [ 9616/23057]
loss: 0.298192  [11216/23057]
loss: 0.693437  [12816/23057]
loss: 0.140073  [14416/23057]
loss: 0.148064  [16016/23057]
loss: 0.283951  [17616/23057]
loss: 0.375326  [19216/23057]
loss: 0.226890  [20816/23057]
loss: 0.257839  [22416/23057]
Validation Loss: 0.3359, Accuracy: 0.8672, F1 Score: 0.6901
Epoch 2
-------------------------------
loss: 0.310982  [   16/23057]
loss: 0.289842  [ 1616/23057]
loss: 0.456276  [ 3216/23057]
loss: 0.416503  [ 4816/23057]
loss: 0.054368  [ 6416/23057]
loss: 0.285107  [ 8016/23057]
loss: 0.204429  [ 9616/23057]
loss: 0.167691  [11216/23057]
loss: 0.082259  [12816/23057]
loss: 0.316214  [14416/23057]
loss: 0.514407  [16016/23057]
loss: 0.292140  [17616/23057]
loss: 0.243171  [19216/23057]
loss: 0.170867  [20816/23057]
loss: 0.216116  [22416/23057]
Validation Loss: 0.2227, Accuracy: 0.9137, F1 Score: 0.8314
Epoch 3
-------------------------------
loss: 0.093358  [   16/23057]
loss: 0.083870  [ 1616/23057]
loss: 0.082107  [ 3216/23057]
loss: 0.102717  [ 4816/23057]
loss: 0.289931  [ 6416/23057]
loss: 0.076078  [ 8016/23057]
loss: 0.294399  [ 9616/23057]
loss: 0.573560  [11216/23057]
loss: 0.044354  [12816/23057]
loss: 0.427303  [14416/23057]
loss: 0.017675  [16016/23057]
loss: 0.653194  [17616/23057]
loss: 0.026494  [19216/23057]
loss: 0.050003  [20816/23057]
loss: 0.199640  [22416/23057]
Validation Loss: 0.1376, Accuracy: 0.9444, F1 Score: 0.8944
Epoch 4
-------------------------------
loss: 0.127459  [   16/23057]
loss: 0.078890  [ 1616/23057]
loss: 0.026930  [ 3216/23057]
loss: 0.051199  [ 4816/23057]
loss: 0.062401  [ 6416/23057]
loss: 0.075452  [ 8016/23057]
loss: 0.090838  [ 9616/23057]
loss: 0.008576  [11216/23057]
loss: 0.120571  [12816/23057]
loss: 0.139565  [14416/23057]
loss: 0.487477  [16016/23057]
loss: 0.218752  [17616/23057]
loss: 0.004920  [19216/23057]
loss: 0.313877  [20816/23057]
loss: 0.022080  [22416/23057]
Validation Loss: 0.1682, Accuracy: 0.9292, F1 Score: 0.8714
Epoch 5
-------------------------------
loss: 0.086019  [   16/23057]
loss: 0.033077  [ 1616/23057]
loss: 0.088101  [ 3216/23057]
loss: 0.124205  [ 4816/23057]
loss: 0.013844  [ 6416/23057]
loss: 0.024744  [ 8016/23057]
loss: 0.001585  [ 9616/23057]
loss: 0.073381  [11216/23057]
loss: 0.005761  [12816/23057]
loss: 0.027987  [14416/23057]
loss: 0.051687  [16016/23057]
loss: 0.062727  [17616/23057]
loss: 0.195665  [19216/23057]
loss: 0.163282  [20816/23057]
loss: 0.012782  [22416/23057]
Validation Loss: 0.1594, Accuracy: 0.9385, F1 Score: 0.8862
Epoch 6
-------------------------------
loss: 0.013019  [   16/23057]
loss: 0.011374  [ 1616/23057]
loss: 0.059413  [ 3216/23057]
loss: 0.028970  [ 4816/23057]
loss: 0.026545  [ 6416/23057]
loss: 0.053730  [ 8016/23057]
loss: 0.007318  [ 9616/23057]
loss: 0.009311  [11216/23057]
loss: 0.013841  [12816/23057]
loss: 0.081430  [14416/23057]
loss: 0.036853  [16016/23057]
loss: 0.163289  [17616/23057]
loss: 0.063274  [19216/23057]
loss: 0.156441  [20816/23057]
loss: 0.002661  [22416/23057]
Validation Loss: 0.1955, Accuracy: 0.9319, F1 Score: 0.8794
Epoch 7
-------------------------------
loss: 0.010009  [   16/23057]
loss: 0.017641  [ 1616/23057]
loss: 0.015745  [ 3216/23057]
loss: 0.063418  [ 4816/23057]
loss: 0.030291  [ 6416/23057]
loss: 0.000252  [ 8016/23057]
loss: 0.023888  [ 9616/23057]
loss: 0.026852  [11216/23057]
loss: 0.704455  [12816/23057]
loss: 0.015626  [14416/23057]
loss: 0.034407  [16016/23057]
loss: 0.160506  [17616/23057]
loss: 0.169498  [19216/23057]
loss: 0.028447  [20816/23057]
loss: 0.021506  [22416/23057]
Validation Loss: 0.1292, Accuracy: 0.9542, F1 Score: 0.9118
Epoch 8
-------------------------------
loss: 0.001679  [   16/23057]
loss: 0.071169  [ 1616/23057]
loss: 0.002972  [ 3216/23057]
loss: 0.008261  [ 4816/23057]
loss: 0.017130  [ 6416/23057]
loss: 0.013339  [ 8016/23057]
loss: 0.001738  [ 9616/23057]
loss: 0.005276  [11216/23057]
loss: 0.003820  [12816/23057]
loss: 0.000644  [14416/23057]
loss: 0.221587  [16016/23057]
loss: 0.030954  [17616/23057]
loss: 0.026581  [19216/23057]
loss: 0.020697  [20816/23057]
loss: 0.059924  [22416/23057]
Validation Loss: 0.1388, Accuracy: 0.9441, F1 Score: 0.8981
Epoch 9
-------------------------------
loss: 0.072178  [   16/23057]
loss: 0.011390  [ 1616/23057]
loss: 0.005646  [ 3216/23057]
loss: 0.000149  [ 4816/23057]
loss: 0.027752  [ 6416/23057]
loss: 0.019148  [ 8016/23057]
loss: 0.016154  [ 9616/23057]
loss: 0.068969  [11216/23057]
loss: 0.084734  [12816/23057]
loss: 0.183490  [14416/23057]
loss: 0.017458  [16016/23057]
loss: 0.002357  [17616/23057]
loss: 0.276965  [19216/23057]
loss: 0.015391  [20816/23057]
loss: 0.105480  [22416/23057]
Validation Loss: 0.1267, Accuracy: 0.9575, F1 Score: 0.9156
Epoch 10
-------------------------------
loss: 0.032919  [   16/23057]
loss: 0.007135  [ 1616/23057]
loss: 0.006157  [ 3216/23057]
loss: 0.032311  [ 4816/23057]
loss: 0.014173  [ 6416/23057]
loss: 0.055347  [ 8016/23057]
loss: 0.026434  [ 9616/23057]
loss: 0.020229  [11216/23057]
loss: 0.057071  [12816/23057]
loss: 0.004284  [14416/23057]
loss: 0.000662  [16016/23057]
loss: 0.001375  [17616/23057]
loss: 0.365699  [19216/23057]
loss: 0.007992  [20816/23057]
loss: 0.023399  [22416/23057]
Validation Loss: 0.0995, Accuracy: 0.9634, F1 Score: 0.9294